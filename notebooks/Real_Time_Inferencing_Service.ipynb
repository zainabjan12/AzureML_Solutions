{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80a1fa6",
   "metadata": {},
   "source": [
    "# Azure Real Time Diabetes Predictions Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488dc4fa",
   "metadata": {},
   "source": [
    "Developed a real-time diabetes prediction solution using Azure ML. Steps include connecting to the workspace, creating a compute cluster, preparing data, training a logistic regression model, deploying it as a web service, orchestrating an inference pipeline, and conducting real-time predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import os\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e55f6",
   "metadata": {},
   "source": [
    "#### Connecting to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93997c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21fb29",
   "metadata": {},
   "source": [
    "#### Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14829b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7031201",
   "metadata": {},
   "source": [
    "#### View Azure Machine Learning resources in the workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compute Resources:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1ffc4",
   "metadata": {},
   "source": [
    "#### Create Datastore and Upload Tabular Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19197de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.core import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "Dataset.File.upload_directory(src_dir='./diabetes-data/',\n",
    "                              target=DataPath(default_ds, 'diabetes-data/')\n",
    "                              )\n",
    "\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, './diabetes-data/*.csv'))\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52490422",
   "metadata": {},
   "source": [
    "## Define an environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acdc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\",\"./experiment_env.yml\")\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306deb4f",
   "metadata": {},
   "source": [
    "## Register the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'experiment_env')\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9444ac1",
   "metadata": {},
   "source": [
    "### Train Model using sript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='./training_folder/',\n",
    "                              script='lg_training_script.py',\n",
    "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
    "                                           '--input-data', diabetes_ds.as_named_input('training_data')],\n",
    "                              environment=registered_env,\n",
    "                              docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "                              compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35ff7c",
   "metadata": {},
   "source": [
    "### Register the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "run.register_model(model_path='./outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe0cd1",
   "metadata": {},
   "source": [
    "## Deploy the model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a96b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ed413",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_folder = './diabetes_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\n",
    "service_env.inferencing_stack_version=\"latest\"\n",
    "\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script='./training_folder/score_diabetes.py',\n",
    "                                   environment=service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"diabetes-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305bf07",
   "metadata": {},
   "source": [
    "### Use Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a6d1a",
   "metadata": {},
   "source": [
    "## Creating Batch Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = './batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ed3d6",
   "metadata": {},
   "source": [
    "Using a ParallelRunStep in a pipeline allows for faster batch predictions by processing data in parallel. The results are then combined into a single output file, named parallel_run_step.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dae785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"./training_folder/batch_score_diabetes.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=registered_env,\n",
    "    compute_target=inference_cluster,\n",
    "    node_count=2)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-diabetes',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49185bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bd35b",
   "metadata": {},
   "source": [
    "### Retrive the output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./diabetes-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "for root, dirs, files in os.walk('./diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc84489",
   "metadata": {},
   "source": [
    "### Publish the pipeline and use it as Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef0b4b",
   "metadata": {},
   "source": [
    "Authentication using Interactive Login  and initiates a pipeline run using a REST API call, obtaining the run ID for tracking the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header ready.')\n",
    "\n",
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea92a6e",
   "metadata": {},
   "source": [
    "Since we have the run ID, we can use the **RunDetails** widget to view the experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ec2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\n",
    "\n",
    "# Block until the run completes\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e15e48",
   "metadata": {},
   "source": [
    "Download the output of the pipeline's first step, and display the first 20 results from the 'parallel_run_step.txt' file in a formatted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfa53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the local results folder if left over from a previous run\n",
    "shutil.rmtree('./diabetes-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# Traverse the folder hierarchy and find the results file\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# Display the first 20 results\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
