{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80a1fa6",
   "metadata": {},
   "source": [
    "# Azure Real Time Diabetes Predictions Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488dc4fa",
   "metadata": {},
   "source": [
    "#  Project Overview\n",
    "In this Azure ML initiative, our objective is to leverage Azure Machine Learning to develop a comprehensive real-time diabetes prediction solution. Key phases include establishing a connection to the Azure ML workspace, creating a compute cluster, preparing data, training a logistic regression model, and deploying it as a web service. The project concludes with the seamless orchestration of an inference pipeline for efficient real-time predictions on new data, complemented by rigorous testing using the 'requests' module.\n",
    "\n",
    "1. **Connection to Workspace:**\n",
    "   - Establish connection to Azure ML workspace.\n",
    "\n",
    "2. **Creation of  Compute Cluster:**\n",
    "   - Set up compute cluster for model tasks.\n",
    "\n",
    "3. **Data Preparation:**\n",
    "   - Update data to datastore, create tabular dataset.\n",
    "\n",
    "4. **Environment Setup:**\n",
    "   - Define, create, and register environment.\n",
    "\n",
    "5. **Model Training:**\n",
    "   - Train Logistic Regression model with parameterized inputs.\n",
    "\n",
    "6. **Model Registration:**\n",
    "   - Register the trained model in the workspace.\n",
    "\n",
    "7. **Scoring Script:**\n",
    "   - Create script for real-time predictions.\n",
    "\n",
    "8. **Inference Pipeline:**\n",
    "   - Orchestrate deployment environment.\n",
    "\n",
    "9. **Model Deployment:**\n",
    "   - Deploy the registered model as a web service.\n",
    "\n",
    "10. **Real-time Predictions:**\n",
    "    - Utilize web service for predictions on new data.\n",
    "\n",
    "11. **Testing with 'requests' Module:**\n",
    "    - Use 'requests' to hit the endpoint and retrieve results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13f299",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e55f6",
   "metadata": {},
   "source": [
    "#### Connecting to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93997c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21fb29",
   "metadata": {},
   "source": [
    "### Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14829b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7031201",
   "metadata": {},
   "source": [
    "#### View Azure Machine Learning resources in the workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compute Resources:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1ffc4",
   "metadata": {},
   "source": [
    "### Update Data to Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19197de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3f5fa",
   "metadata": {},
   "source": [
    "### Create Tabular Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69073c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52490422",
   "metadata": {},
   "source": [
    "## Define an environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acdc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306deb4f",
   "metadata": {},
   "source": [
    "## Register the environment\n",
    "\n",
    "Having gone to the trouble of defining an environment with the packages you need, you can register it in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the environment\n",
    "experiment_env.register(workspace=ws)\n",
    "# get the registered environment\n",
    "registered_env = Environment.get(ws, 'experiment_env')\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9444ac1",
   "metadata": {},
   "source": [
    "### Train Model using sript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory='training_folder/',\n",
    "                              script='lg_training_script.py',\n",
    "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
    "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                              environment=env,\n",
    "                              docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "                              compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35ff7c",
   "metadata": {},
   "source": [
    "### Register the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe0cd1",
   "metadata": {},
   "source": [
    "## Deploy the model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a96b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ed413",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './diabetes_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_diabetes.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\n",
    "service_env.inferencing_stack_version=\"latest\"\n",
    "\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"diabetes-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305bf07",
   "metadata": {},
   "source": [
    "### Use Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a6d1a",
   "metadata": {},
   "source": [
    "### Creating Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b5c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
